{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Enconder Variacional (VAE)\n",
    "\n",
    "~~~\n",
    "Extracción de Características en Imágenes.\n",
    "Master en Ciencia de Datos y Arquitectura de los Computadores.\n",
    "Universidad de Granada.\n",
    "\n",
    "Fernando Pérez Bueno - fpb@ugr.es\n",
    "Rafael Molina Soriano - rms@decsai.ugr.es\n",
    "\n",
    "~~~\n",
    "\n",
    "En este guión veremos la implementación de una VAE en Keras. \n",
    "Esta implementación ha sido obtenida de los ejemplos de Keras\n",
    "https://keras.io/examples/generative/vae/\n",
    "\n",
    "En el post de towardsdatascience.com hay una explicación muy intuitiva y contiene algunos de los ejemplos que se han mencionado en clase.\n",
    "https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf\n",
    "\n",
    "En este enlace puedes visualizar el contenido del espacio latente de una VAE entrenada con MNIST\n",
    "http://taylordenouden.com/VAE-Latent-Space-Explorer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerias que vamos a utilizar en el desarrollo de la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tu versión de tensorflow: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf # versión minima para este codigo, tensorflow 2.2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Tu versión de tensorflow:',tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLOQUE 1. Preguntas generales sobres las VAEs. Valor total de las respuestas 1 sobre 2 puntos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de MNIST\n",
    "\n",
    "Las redes neuronales requieren una cantidad de datos muy elevada para entrenar, por tanto, nuestro dataset de tan solo 5000 caras se queda pequeño. En esta ocasión vamos a trabajar con el popular dataset MNIST, que probablemente ya conozcas. Se trata de imágenes 28x28 de números manuscritos, con un total de 70.000 muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).\\\n",
    "            astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_digits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_digitos=5\n",
    "for i in range(n_digitos):\n",
    "    plt.subplot(1,n_digitos,i+1)\n",
    "    plt.imshow(mnist_digits[i,...,0],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capa de muestreo\n",
    "\n",
    "La capa de muestreo, nos permite extraer muestras de p(z|x) mediante la trampa de la reparametrización. Fijate que definimos como se obtiene una muestra utilizando una capa de tensorflow, para poder integrarla en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.\\\n",
    "        random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construimos el codificador (Encoder)\n",
    "\n",
    "Utilizaremos una red neuronal que será la encargada de representar p(z|x). Fijate que le pedimos dos salidas, media y varianza para explicar la variable latente.\n",
    "\n",
    "La arquitectura es sencilla:\n",
    "\n",
    "1. Comenzamos con imagenes en blanco y negro de 28x28 pixel\n",
    "2. Una capa convolucional de 32 filtros 3x3 y tamaño de paso (stride) 2 . En los bordes, los filtros se rellenan con duplicados del valor del borde. Nuestro tamaño es ahora 32x14x14. Fijate que hemos usado una función de activación muy extendida, la ReLU\n",
    "3. Una nueva capa convolucional de 63 filtros 3x3 y stride 2.\n",
    "4. Una capa \"flatten\" para convertir cada conjunto de caracteristicas extraidas por los filtros en un vector.\n",
    "5. Una capa intermedia, totalmente conectada, que comprime las caracteristicas a 16.\n",
    "6. De forma paralela, la red se divide en dos:\n",
    "    1. Una red totalmente conectada que extrae la media z según el tamaño de dimension latente especificado\n",
    "    2. Una red totalmente conectada que extrae la varianza de z según el tamaño de dimensión latente. (Elementos de la diagonal)\n",
    "7. Usando la función sampling que hemos definido en el paso anterior, obtenemos una muestra de z.\n",
    "\n",
    "Observa que la orden encoder.summary() nos permite ver claramente el tamaño de nuestros datos en cada paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z],name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> Dibuja la estructura del codificador. Puedes hacerlo a mano, luego hacerle una foto al gráfico e incluirlo aquí. Si lo prefieres utiliza alguna aplicación gráfica para dibujar la red. Del codificador no es necesario que incluyas la generación de la muestra.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluye aquí tu gráfico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Construcción del decoder\n",
    "\n",
    "De la misma forma, construimos el decodificador que será p(x|z).\n",
    "\n",
    "La estructura es similar:\n",
    "\n",
    "0. Partimos de una muestra de z.\n",
    "1. Una capa totalmente conectada, que obtiene un vector 7*7*64\n",
    "2. Una redimensión para convertirla a las dimensiones con las que trabajan las capas convolucionales.\n",
    "3. Una capa de convolución transpuesta de 64 filtros 3x3 y stride 2. En este caso, quiere decir que la salida será el doble del tamaño de la entrada.\n",
    "4. Una capa de convolución transpuesta de 32 filtros 3x3 y de nuevo stride 2.\n",
    "5. Una ultima capa de convolución transpuesta de 1 solo filtro 3x3. Fijate que ya teniamos el tamaño 28x28 y lo que hace esta capa es unificar las características de los 32 filtros a una sola imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> Dibuja la estructura del decodificador. Puedes hacerlo a mano, luego hacerle una foto al gráfico e incluirlo aquí. Si lo prefieres utiliza alguna aplicación gráfica para dibujar la red. </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluye aquí el decodificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> En la última capa, hemos utilizado una sigmoide. ¿por qué lo hemos hecho?, ¿podríamos haber usado una RELU?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu respuesta\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definimos la VAE y su entrenamiento\n",
    "\n",
    "Tenemos definidos codificador y decodificador como modelos separados. En este paso construimos una VAE que unira ambos modelos.\n",
    "\n",
    "A la hora de entrenar la VAE, recuerda que usamos tanto el error de reconstrucción como la divergencia de Kullback-Leibler. Los pasos se especifican en la función train_step():\n",
    "1. Usar el encoder para obtener z_mean, z_log_var y una muestra de z, a partir de los datos.\n",
    "2. Usar el decoder para obtener la reconstrucción de los datos, a partir de nuestra z muestreada.\n",
    "3. Calcular la función de perdida:\n",
    "    1. Error de reconstrucción\n",
    "    2. Divergencia de Kullback-Leibleer\n",
    "    3. Perdida total (Suma de las anteriores)\n",
    "4. Calculamos y aplicamos los gradientes para optimizar los parametros de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> Explica con tus propias palabras por qué es necesario incluir la divergencia de Kullback-Leibler en la función de perdida.\n",
    "\n",
    "¿Que efecto tiene utilizar solo el error de reconstrucción?\n",
    "\n",
    "¿Y si usamos tan solo la divergencia de Kullback-Leibler?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INCLUYE TU RESPUESTA AQUÍ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos la VAE usando MNIST\n",
    "\n",
    "En este paso creamos una VAE con el encoder y el decoder que hemos definido al principio de la práctica. Definimos el optimizador a utilizar para aplicar gradiente descendente (Adam) y ajustamos los parametros de la VAE para representar correctamente el dataset MNIST.\n",
    "\n",
    "Ejecutar está celda te llevará un rato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Es necesario fijar la semilla de numpy y la de tensorflow para obtener resultados reproducibles.\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(mnist_digits, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> ¿Por qué la perdida de reconstrucción disminuye en cada epoca mientras que la de KL aumenta? (Pregunta Obligatoria)\n",
    "</b>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>\n",
    "\n",
    "Otras cuestiones que puedes plantearte sobre el proceso de entrenamiento (Preguntas Opcionales)  \n",
    "  \n",
    "¿Qué factores determinan el batch_size y el número de épocas?  \n",
    "¿Cuanto se modifican los parametros de la red en cada paso? ¿Donde hemos especificado el learning rate?  \n",
    "¿Por qué cada epoca tiene 547 iteraciones?  \n",
    "\n",
    "</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizacion del contenido del espacio latente\n",
    "\n",
    "Como hemos diseñado nuestro modelo para que el espacio latente tenga 2 componentes, podemos visualizar las medias que toma z. Las obtenemos aplicando el encoder que hemos entrenado y a cada punto le asignamos el color que corresponde con su etiqueta. Como ves, hemos cargado de nuevo los datos para obtener también su etiqueta.\n",
    "\n",
    "La función plot_label_clusters() siguiente muestra cada media de un color diferente según su etiqueta. Hemos incluido un cuadrado que te facilitará entender el apartado siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
    "z_mean, _, _ = vae.encoder.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_label_clusters(z_mean, labels):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "#     z_mean, _, _ = vae.encoder.predict(data)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    cmap=plt.get_cmap('tab10', 10)\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels, cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    rectangle = plt.Rectangle((-1,-1), 2, 2,ec=\"black\",fill=False)\n",
    "    plt.gca().add_patch(rectangle)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label_clusters(z_mean, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> Si quisieramos usar las z para clasificar nuestros datos, ¿Qué clases se distinguen mejor? ¿Como crees que afectaria cambiar la dimensión del espacio latente?</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluye tu respuesta aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizacion del contenido del espacio latente II\n",
    "\n",
    "Hemos visto que distribución tienen los datos que hemos observado en el espacio latente. ¿Pero cual es el aspecto que tiene el espacio latente al volver al dominio de imagen?\n",
    "\n",
    "En este caso, recorremos el espacio latente en las dos dimensiones, tomando valores en [-1,1] para cada dimensión de z. Haciendo uso del decoder, obtenemos los digitos que corresponden a las z que hemos generado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space(vae, n=30, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    digit_size = 28\n",
    "    scale = 1.0\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = vae.decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent_space(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> ¿Por que faltan dígitos en esta representación? ¿Por qué algunos dígitos aparecen muy definidos mientras que otros aparecen borrosos</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De principio a fin\n",
    "\n",
    "Con los digitos que te damos a continuación. Utiliza encoder y decoder para mostrar en 10 pasos, como convertir el primero en el segundo.\n",
    "\n",
    "Necesitaras:\n",
    "\n",
    "1. Obtener sus correspondientes distribuciones de z\n",
    "2. Utilizando la media de las distribuciónes, desplazarte en el espacio latente desde una a la otra. Generando 10 muestras de z.\n",
    "3. Reconstruir los dígitos correspondientes a las z que has generado\n",
    "4. Mostrar los 10 dígitos que has obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_muestras=x_train[3:5,:,:,0]\n",
    "print(x_muestras.shape)\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(x_muestras[i,:,:],cmap='gray')# ,0])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLOQUE 2. Sobre la trampa de la reparametrización. Valor de la solución 1 sobre 2 puntos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio debes usar la trampa de la reparametrización para estimar los parámetros de un modelo PPCA muy sencillo.\n",
    "\n",
    "Comenzaremos generando las muestras de ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6ba452ff10>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n = 1000\n",
    "\n",
    "mu, sigma_prior = 0, 1 # mean and standard deviation\n",
    "Z = np.random.normal(mu, sigma_prior, n)  # n muestras de la a priori\n",
    "W = np.array([[1],[1]])\n",
    "W=W/np.sqrt(2)  # vector unitario de tamaño 2x1\n",
    "\n",
    "sigma_noise=0.1\n",
    "\n",
    "# Generamos las muestras. Cada columna de X que tiene tamaño 2xn contendrá una\n",
    "X = Z*W+np.random.normal(mu,sigma_noise,n*2).reshape(2,n) \n",
    "\n",
    "plt.plot(X[0],X[1],'o')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando solo las observaciones X, ¿Cómo estimarías W, sigma_noise y dado un x la distribución p(z|x) mediante la trampa de la reparametrización?\n",
    "\n",
    "Como estamos intentando emular un modelo PPCA supondremos que $p(z|x)={\\cal N}(m_1x_1+m_2x_x,(\\mbox{sigma_post})^2)$ y tendrás que estimar $m_1$, $m_2$ y $\\mbox{sigma_post}$. Obviamente no puedes usar una VAE para este problema. Debes usar la fórmula de la divergencia de Kullback-Leibler y el muestreo solo usarlo para la parte de las observaciones. Puedes usar como tamaño de batch el conjunto completo de muestras. Explica en el código los pasos que vas dando.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> Estima W, sigma_noise, $m_1$, $m_2$ y sigma_post usando la trampa de la reparametrización</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
